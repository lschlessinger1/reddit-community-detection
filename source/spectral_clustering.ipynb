{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import user-subreddit post behavior\n",
    "accounts = {}\n",
    "with open('data/reddit-user-posting-behavior.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    idx = 0\n",
    "    for row in reader:\n",
    "        accounts[idx] = list(set(row[1:]))\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subreddits: 15122\n"
     ]
    }
   ],
   "source": [
    "# get unique subreddits\n",
    "subreddits = list(set([v for values in accounts.values() for v in values]))\n",
    "\n",
    "# map subreddits to index mappings\n",
    "subidx = {}\n",
    "idx_to_sub = {}\n",
    "for i in range(len(subreddits)):\n",
    "    subidx[subreddits[i]] = i\n",
    "    idx_to_sub[i] = subreddits[i]\n",
    "    \n",
    "# print total number of subreddits\n",
    "print('Total subreddits: {}'.format(len(subreddits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sparse cols and rows\n",
    "row = []\n",
    "col = []\n",
    "for user,sublist in accounts.items():\n",
    "    for sub in sublist:\n",
    "        row.append(subidx[sub])\n",
    "        col.append(user)\n",
    "\n",
    "# build subreddit-user relation matrix\n",
    "submat = sparse.csr_matrix((np.ones(len(row)),(row,col)))\n",
    "\n",
    "# create final subreddit-subreddit relations\n",
    "srs = submat*submat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip small degree\n",
    "pmat = srs.toarray()\n",
    "#pmat[pmat < 100] = 0\n",
    "\n",
    "# build percentage matrix\n",
    "diag = 1/srs.diagonal()\n",
    "pmat = np.multiply(pmat,diag.reshape((-1,1)))\n",
    "\n",
    "# threshold percentages\n",
    "pmat[pmat < 0.05] = 0\n",
    "\n",
    "# remove edges that are only one-sided\n",
    "pmat = np.multiply(pmat, pmat.T)\n",
    "pmat = pmat > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "G = nx.from_numpy_matrix(pmat, create_using=nx.Graph())\n",
    "\n",
    "# relabel nodes\n",
    "G = nx.relabel_nodes(G, idx_to_sub)\n",
    "\n",
    "# remove isolates and self edges\n",
    "G.remove_edges_from(list(G.selfloop_edges()))\n",
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find largest connected component\n",
    "cc = [G.subgraph(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally, save largest connected component to gephi file\n",
    "# nx.write_gexf(cc, 'graphs/lcc.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(G, k):\n",
    "    import numpy.linalg as la\n",
    "    import scipy.cluster.vq as vq\n",
    "    \n",
    "    A = nx.adjacency_matrix(G)\n",
    "    D = np.diag(np.ravel(np.sum(A, axis=1)))\n",
    "    L = D - A\n",
    "    l, U = la.eigh(L)\n",
    "    f = U[:, 1]\n",
    "    labels = np.ravel(np.sign(f))\n",
    "    \n",
    "    means, labels = vq.kmeans2(U[:, 1:k], k)\n",
    "\n",
    "    communities = [set(np.array(list(G.nodes))[labels == l]) for l in np.unique(labels)]\n",
    "\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lousc\\Anaconda3\\envs\\py3-6\\lib\\site-packages\\scipy\\cluster\\vq.py:525: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    }
   ],
   "source": [
    "# perform spectral clustering\n",
    "ks = np.arange(10, 110, 10)\n",
    "communities = [spectral_clustering(cc, k=k) for k in ks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute modularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5817729235860879,\n",
       " 0.5583046413113081,\n",
       " 0.5092365132409091,\n",
       " 0.5460910766459377,\n",
       " 0.4569773843090959,\n",
       " 0.6827996074173764,\n",
       " 0.6830314680369661,\n",
       " 0.7573878048166258,\n",
       " 0.623084263966161,\n",
       " 0.722571779557198]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modularities = [nx.community.modularity(cc, community) for community in communites]\n",
    "modularities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Conductances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conductances(G, communities):\n",
    "    '''Compute conductance for a list of communities\n",
    "    '''\n",
    "    return [nx.algorithms.cuts.conductance(G, community) for community in communities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductance_list = [conductances(cc, c) for c in communites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 19, 23, 34, 43, 56, 58, 68, 74, 74]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c) for c in communites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_conductances = []\n",
    "std_conductances = []\n",
    "min_conductances = []\n",
    "for c in conductance_list:\n",
    "    c_arr = np.array(c)\n",
    "    avg_conductances.append(np.average(c_arr))\n",
    "    std_conductances.append(np.std(c_arr))\n",
    "    min_conductances.append(np.min(c_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03069345207304954,\n",
       " 0.058423343963943,\n",
       " 0.05093264542583004,\n",
       " 0.055343889178186056,\n",
       " 0.0698631236918335,\n",
       " 0.08400994111488691,\n",
       " 0.05934504553416607,\n",
       " 0.07303860485284937,\n",
       " 0.08096740442306477,\n",
       " 0.0737842990371654]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_conductances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.019883410920741567,\n",
       " 0.06034318151545104,\n",
       " 0.041189166841016214,\n",
       " 0.034412520929908846,\n",
       " 0.05892564476467786,\n",
       " 0.12994859116261573,\n",
       " 0.026865829723147154,\n",
       " 0.05495181958573338,\n",
       " 0.06329756360546539,\n",
       " 0.04529635438226902]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_conductances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010024269283528543,\n",
       " 0.011985181956853346,\n",
       " 0.014084507042253521,\n",
       " 0.011235955056179775,\n",
       " 0.02564102564102564,\n",
       " 0.011235955056179775,\n",
       " 0.01406799531066823,\n",
       " 0.011235955056179775,\n",
       " 0.01898333684876608,\n",
       " 0.014889577295892875]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_conductances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
